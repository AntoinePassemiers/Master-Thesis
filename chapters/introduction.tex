\chapter{Introduction}

\section{Background and objectives of the thesis}

    \setcounter{page}{1}
    \vspace*{0.5cm}

    Proteins are large macromolecules in the form of chains of building blocks called amino acid residues.
    There are 20 common amino acid types, but certain proteins may contain 2 additional amino acid types, namely pyrrolysine and selenocystein.
    According to Anfinsen's dogma, the three-dimensional structure of a protein is uniquely determined by its underlying amino acid sequence,
    at least when observed in protein's native environment. When moved from an environment where proper folding conditions are not met
    to a solvent at neutral pH, a random coil (a sequence of amino acid residues
    oriented in random directions) will evolve towards the three-dimensional structure that minimizes Gibbs free energy.
    This process is called protein folding and has, however, a few exceptions.

    Assuming the protein backbone has no structural restriction and is composed of $n$ residues holded together by $n-1$ peptide bonds,
    then the protein has $2(n-1)$ bond angles that can be each in three different stable states. Therefore, there are at most
    $3^{2(n-1)}$ possible configurations, and it would take the age of the universe to find the correct folding by enumeration.
    There is strong evidence that protein folding is a NP-hard problem~\cite{hart1997robust}.
    However, in practice small proteins are able to fold into a stable conformation in a fraction of a millisecond.
    This observation is known as the Levinthal's paradox. There has been a long standing perspective that protein folding
    is guided by heuristics composed of local interactions~\cite{levinthal1969fold}. Heuristic folding leads to misfolded proteins
    that can potentially cause genetic diseases. Luckily, some proteins are assisted by molecular chaperones during their folding process~\cite{ellis1991molecular}
    to attain their functional conformation. It must be noted that Anfinsen's observations of polypeptide chains refolding spontaneously in an aqueous medium
    have been made in the framework of in vitro studies: they do not take into account protein-protein interations and thus cannot generalize the
    self-assembly process well.

    Protein Contact Prediction (PCP) can help determining the three-dimensional structure of proteins by limiting the search space to certain conformations
    constrained by predicted contact maps: this methodology is called contact-assisted protein folding.
    The problem of predicting the structure of a protein can be reduced to PCP because the latter is a much simpler problem,
    and only a few correctly predicted contacts are sufficient to reconstruct the whole structure~\cite{kim2014one}.

    Structure-based methods are important in biology, as they help in assigning biochemical or biological functions to proteins. Indeed, the three-dimensional
    structure of a protein is more well conserved than the underlying amino acid sequence across evolution. Prompted by this knowledge, similar functions
    can be assigned to proteins with low structural dissimilarity. Precisely identifying the role played by each protein in an organism is the first step
    towards understanding complex body mechanisms like muscle contraction, digestion or perceiving light.
    Also, determining the static structure of proteins help in detecting misfolded proteins which are possibly involved in diseases like Parkinson's or
    Alzheimer's, but also in diagnosing those diseases.
    Finally, solving the protein folding (structure prediction) problem will enable to do better protein design, for example to engineer enzymes like PETase
    so they have faster pastic-degrading capabilities.
    There are pipelines designed to predict the structure and then the function of a newly
    observed protein, such as RaptorX server~\cite{peng2011raptorx}.

    Protein structure is organized hierarchically: primary structure, secondary structure, tertiary structure
    and quaternary structure. Primary structure refers to the chemical composition of the protein, hence the sequence of amino acids present in it.
    Secondary structure indicates the presence of structures that are local to the amino acids themselves: these structures can generally be $\alpha$-helices
    or $\beta$-sheets. Tertiary structure contains information about the three-dimensional structure of the protein and results from interactions
    between side chains of some pairs of amino acids, such as hydrogen bonds, ionic bonds or disulfide bridges.
    Quaternary structure is specific to proteins having multiple polypeptide chains and describes the structure due to intermolecular interactions between
    these chains. PCP helps predicting the tertiary structure since three-dimensional models can be reconstructed from protein contact maps (PCM).
    Also, PCM is a more simplistic and robust description of a protein's geometry because it is invariant to rotations and translations.
    This simplification helps making deep learning methods perform well on structure prediction.

    Most PCP methods can be roughly divided into two categories:
    the ones based on Evolutionary Coupling Analysis (ECA) and the ones that infer contacts using
    supervised machine learning. In the former case, amino acid pairwise mutations are statistically modelled and the underlying model's parameters
    are generally optimized through log-likelihood maximization. In the second case, deep neural architectures are used to
    refine predictions made by low-level predictors such as ECA, in order to generate high-quality contact maps.

    Ultimately, PCP should help making \textit{ab initio} structure prediction.
    However, most recent methods rely on a whole raft of alignment and prediction tools.
    Given a protein encoded in FASTA format, ECA is only possible using a Multiple Sequence Alignment (MSA)
    of this target protein against homologuous proteins. These homologuous proteins come from the same protein family
    as the target protein, and therefore the most suitable family must be found.
    This can be done by matching the target sequence to a Hidden Markov Model (HMM) profile representing a family
    like in Pfam database~\cite{Pfam}. Once the homologuous sequences have been retrieved, they have to be aligned to
    the target sequence using an MSA tool like HHblits or HMMER. In the next step, evolutionary couplings are extracted from
    the MSA using an ECA predictor like PSICOV~\cite{doi:10.1093/bioinformatics/btr638} or plmDCA~\cite{EKEBERG2014341}.
    Eventually, predictions are gathered and refined using a deep neural architecture, necessitating the use
    of a deep learning framework. These successive layers of dependencies are not making PCP a straightforward process.
    Therefore, it seems to be a natural choice to set as an objective for this thesis the development of a predictor with
    minimal requirements and performance close to state-of-the-art techniques
    \cite{RaptorX, DeepContact, doi:10.1093/bioinformatics/bty341, doi:10.1093/bioinformatics/bty341, Michel383133, DeepMind}.

\section{Structure of the thesis}

    Let me describe the global view of the thesis itself.
    Firstly, common state-of-the-art ECA techniques will be described, such as Direct Coupling Analysis (DCA)
    and Pseudo-Inverse Covariance matrices (PSICOV) (both are statistical methods based on graphical models),
    as well as the basics of deep learning and backpropagation algorithm.
    In order to gain a deeper insight on best-performing methods, more details will be given for
    some specific deep learning methods, such as their architecture, input features and preprocessing.
    The generic architecture in use for this thesis will be detailed, as well as the hyper-parameter
    optimization procedure used for cross-validation.
    Finally, results will be presented in multiple sections:
    \begin{itemize}
        \item Since the proposed deep learning approach relies on DCA predictions as input features,
        the first step should be to demonstrate that deep learning is capable of refining
        contact maps by looking at complex visual patterns that cannot captured by linear models.
        \item It should be brought to light whether deep learning's performance is less sensitive to the effective
        number of homologous sequences than DCA methods. The notion of effective number of homologous sequences
        will be introduced in section \ref{meff}.
        \item Finally, a benchmark will be established to assess the performance of the proposed method
        and other supervised approaches,
        to the extent possible, state-of-the-art deep learning architectures.
    \end{itemize}

\section{Contributions}

    \todo{}
